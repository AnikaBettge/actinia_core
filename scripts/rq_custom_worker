#!/usr/bin/env python
# -*- coding: utf-8 -*-
import sys
from rq import Connection, Worker
import actinia_core
# We need to append the path to the actinia_core package, since
# flask API does not send the correct module and package paths
# to the worker, so the workers are unable to de-serialize
# tha object that are required by the asynchronous process classes.
from os.path import dirname

sys.path.append(dirname(actinia_core.__file__))
# Integrate the fluentd logger into the logging infrastructure
# https://github.com/fluent/fluent-logger-python
import logging
import logging.handlers
from actinia_core.resources.common.config import Configuration
import os
import argparse
import sys
import platform

has_fluent = False

try:
    from fluent import handler
    has_fluent = True
except:
    print("Fluent is not available")
    has_fluent = False

__license__ = "GPLv3"
__author__     = "Sören Gebbert"
__copyright__  = "Copyright 2016, Sören Gebbert"
__maintainer__ = "Sören Gebbert"
__email__      = "soerengebbert@googlemail.com"


def main():

    parser = argparse.ArgumentParser(description='Start a single Actinia Core '
                                                 'custom worker listening to a specific queue.'
                                                 'It uses the logfile settings that are specified '
                                                 'in the default GRaaS configuration file'
                                                 'or a file specified by an optional path.')

    parser.add_argument("queue", type=str,
                        help="The name of the queue that should be listen to by the worker")
    parser.add_argument("-c", "--config", type=str, required=False,
                        help="The path to the Actinia Core configuration file")

    args = parser.parse_args()

    # Provide queue names to listen to as arguments to this script,
    # similar to rq worker
    with Connection():

        conf = Configuration()
        try:
            if args.config and os.path.isfile(args.config):
                conf.read(path=args.config)
            else:
                conf.read()
        except IOError as e:
            print("Unable to read config file, will use defaults instead, IOError: %s"%str(e))

        logger = logging.getLogger('rq.worker')
        logger.setLevel(logging.ERROR)

        node = platform.node()

        if conf.LOG_INTERFACE == "fluentd" and has_fluent is True:
            custom_format = {
                'host': '%(hostname)s',
                'where': '%(module)s.%(funcName)s',
                'status': '%(levelname)s',
                'stack_trace': '%(exc_text)s'
            }
            fh = handler.FluentHandler('%s::rq.worker'%node,
                                       host=conf.LOG_FLUENT_HOST,
                                       port=conf.LOG_FLUENT_PORT)
            formatter = handler.FluentRecordFormatter(custom_format)
            fh.setFormatter(formatter)
            logger.addHandler(fh)

        # Add the log message handler to the logger
        log_file_name = '%s_%s.log'%(conf.WORKER_LOGFILE, args.queue)
        lh = logging.handlers.RotatingFileHandler(log_file_name,
                                                  maxBytes=2000000,
                                                  backupCount=5)
        logger.addHandler(lh)

        w = Worker([args.queue,])
        w.work()


if __name__ == '__main__':
    main()
